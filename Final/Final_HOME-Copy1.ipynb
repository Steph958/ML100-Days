{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D \n",
    "from keras.layers import MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.layers import BatchNormalization, Flatten, Conv2D, AveragePooling2D \n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.initializers import glorot_uniform\n",
    "from resnet import ResnetBuilder\n",
    "from resnet_builder import resnet\n",
    "import os\n",
    "# from resnet_builder import resnet\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(\"../data\")\n",
    "ROOT_DIR\n",
    "TRAIN_DIR = os.path.join(ROOT_DIR, \"train\")\n",
    "TRAIN_DIR\n",
    "TEST_DIR = os.path.join(ROOT_DIR,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\cptien\\\\Desktop\\\\ML100-Days\\\\data\\\\test'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_gen = ImageDataGenerator(rotation_range=30,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Generator\n",
    "train_datagen = ImageDataGenerator(rotation_range=20,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                   rescale=1./255,\n",
    "                                   shear_range= 0.2,\n",
    "                                   zoom_range= 0.2,\n",
    "                                   horizontal_flip= True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Misc Information\n",
    "num_classes = 5\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export_results(train, test, model, output_name):\n",
    "    test.reset()\n",
    "    pred = model.predict_generator(test, steps=len(test),verbose=1)\n",
    "    predicted_class_indices= np.argmax(pred, axis=1)\n",
    "    \n",
    "    labels = (train.class_indices)\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    predictions = [labels[k] for k in predicted_class_indices]\n",
    "    \n",
    "    test_path=test.filenames\n",
    "    filenames=[]\n",
    "    for n in test_path:\n",
    "        seg1, seg2 = n.split(\"/\")\n",
    "        front, back = seg2.split('.')\n",
    "\n",
    "        filenames.append(front)\n",
    "\n",
    "    results= pd.DataFrame({\"id\":filenames,\n",
    "                      \"flower_class\":predicted_class_indices})\n",
    "    results.to_csv(\"./submission\"+str(output_name)+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系統找不到指定的路徑。: 'C:\\\\Users\\\\cptien\\\\Desktop\\\\ML100-Days\\\\data\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e2292cfd3aa5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                           \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                                           class_mode='categorical')\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Load testing set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m   1011\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m             interpolation=interpolation)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m     def flow_from_dataframe(self, dataframe, directory,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m   1873\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1874\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1875\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1876\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1877\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系統找不到指定的路徑。: 'C:\\\\Users\\\\cptien\\\\Desktop\\\\ML100-Days\\\\data\\\\train'"
     ]
    }
   ],
   "source": [
    "# Load training set\n",
    "train = train_datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                          target_size=(64,64), \n",
    "                                          batch_size=32, \n",
    "                                          class_mode='categorical', \n",
    "                                          shuffle=True,\n",
    "                                         )\n",
    "total_samples = train.n\n",
    "# Load testing set\n",
    "test = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                        target_size=(64,64),\n",
    "                                        batch_size=1, \n",
    "                                        class_mode=None,\n",
    "                                        shuffle=False)\n",
    "# train = keras.utils.to_categorical(train, 5)\n",
    "# test = keras.utils.to_categorical(test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor=\"loss\", \n",
    "                          patience=10, \n",
    "                          verbose=1\n",
    "                          )\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.5, \n",
    "                              min_lr=1e-12, \n",
    "                              monitor='loss', \n",
    "                              patience=5, \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_443 (Conv2D)             (None, 32, 32, 64)   9472        input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_407 (BatchN (None, 32, 32, 64)   256         conv2d_443[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_407 (Activation)     (None, 32, 32, 64)   0           batch_normalization_407[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 64)   0           activation_407[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_444 (Conv2D)             (None, 16, 16, 64)   4160        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_408 (BatchN (None, 16, 16, 64)   256         conv2d_444[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_408 (Activation)     (None, 16, 16, 64)   0           batch_normalization_408[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_445 (Conv2D)             (None, 16, 16, 64)   36928       activation_408[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_409 (BatchN (None, 16, 16, 64)   256         conv2d_445[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_409 (Activation)     (None, 16, 16, 64)   0           batch_normalization_409[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_447 (Conv2D)             (None, 16, 16, 256)  16640       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_446 (Conv2D)             (None, 16, 16, 256)  16640       activation_409[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_133 (Add)                   (None, 16, 16, 256)  0           conv2d_447[0][0]                 \n",
      "                                                                 conv2d_446[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_410 (BatchN (None, 16, 16, 256)  1024        add_133[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_410 (Activation)     (None, 16, 16, 256)  0           batch_normalization_410[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_448 (Conv2D)             (None, 16, 16, 64)   16448       activation_410[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_411 (BatchN (None, 16, 16, 64)   256         conv2d_448[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_411 (Activation)     (None, 16, 16, 64)   0           batch_normalization_411[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_449 (Conv2D)             (None, 16, 16, 64)   36928       activation_411[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_412 (BatchN (None, 16, 16, 64)   256         conv2d_449[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_412 (Activation)     (None, 16, 16, 64)   0           batch_normalization_412[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_450 (Conv2D)             (None, 16, 16, 256)  16640       activation_412[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_134 (Add)                   (None, 16, 16, 256)  0           add_133[0][0]                    \n",
      "                                                                 conv2d_450[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_413 (BatchN (None, 16, 16, 256)  1024        add_134[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_413 (Activation)     (None, 16, 16, 256)  0           batch_normalization_413[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_451 (Conv2D)             (None, 16, 16, 64)   16448       activation_413[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_414 (BatchN (None, 16, 16, 64)   256         conv2d_451[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_414 (Activation)     (None, 16, 16, 64)   0           batch_normalization_414[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_452 (Conv2D)             (None, 16, 16, 64)   36928       activation_414[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_415 (BatchN (None, 16, 16, 64)   256         conv2d_452[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_415 (Activation)     (None, 16, 16, 64)   0           batch_normalization_415[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_453 (Conv2D)             (None, 16, 16, 256)  16640       activation_415[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_135 (Add)                   (None, 16, 16, 256)  0           add_134[0][0]                    \n",
      "                                                                 conv2d_453[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_416 (BatchN (None, 16, 16, 256)  1024        add_135[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_416 (Activation)     (None, 16, 16, 256)  0           batch_normalization_416[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_454 (Conv2D)             (None, 8, 8, 128)    32896       activation_416[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_417 (BatchN (None, 8, 8, 128)    512         conv2d_454[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_417 (Activation)     (None, 8, 8, 128)    0           batch_normalization_417[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_455 (Conv2D)             (None, 8, 8, 128)    147584      activation_417[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_418 (BatchN (None, 8, 8, 128)    512         conv2d_455[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_418 (Activation)     (None, 8, 8, 128)    0           batch_normalization_418[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_457 (Conv2D)             (None, 8, 8, 512)    131584      add_135[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_456 (Conv2D)             (None, 8, 8, 512)    66048       activation_418[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_136 (Add)                   (None, 8, 8, 512)    0           conv2d_457[0][0]                 \n",
      "                                                                 conv2d_456[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_419 (BatchN (None, 8, 8, 512)    2048        add_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_419 (Activation)     (None, 8, 8, 512)    0           batch_normalization_419[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_458 (Conv2D)             (None, 8, 8, 128)    65664       activation_419[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_420 (BatchN (None, 8, 8, 128)    512         conv2d_458[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_420 (Activation)     (None, 8, 8, 128)    0           batch_normalization_420[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_459 (Conv2D)             (None, 8, 8, 128)    147584      activation_420[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_421 (BatchN (None, 8, 8, 128)    512         conv2d_459[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_421 (Activation)     (None, 8, 8, 128)    0           batch_normalization_421[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_460 (Conv2D)             (None, 8, 8, 512)    66048       activation_421[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_137 (Add)                   (None, 8, 8, 512)    0           add_136[0][0]                    \n",
      "                                                                 conv2d_460[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_422 (BatchN (None, 8, 8, 512)    2048        add_137[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_422 (Activation)     (None, 8, 8, 512)    0           batch_normalization_422[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_461 (Conv2D)             (None, 8, 8, 128)    65664       activation_422[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_423 (BatchN (None, 8, 8, 128)    512         conv2d_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_423 (Activation)     (None, 8, 8, 128)    0           batch_normalization_423[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_462 (Conv2D)             (None, 8, 8, 128)    147584      activation_423[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_424 (BatchN (None, 8, 8, 128)    512         conv2d_462[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_424 (Activation)     (None, 8, 8, 128)    0           batch_normalization_424[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_463 (Conv2D)             (None, 8, 8, 512)    66048       activation_424[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_138 (Add)                   (None, 8, 8, 512)    0           add_137[0][0]                    \n",
      "                                                                 conv2d_463[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_425 (BatchN (None, 8, 8, 512)    2048        add_138[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_425 (Activation)     (None, 8, 8, 512)    0           batch_normalization_425[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_464 (Conv2D)             (None, 8, 8, 128)    65664       activation_425[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_426 (BatchN (None, 8, 8, 128)    512         conv2d_464[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_426 (Activation)     (None, 8, 8, 128)    0           batch_normalization_426[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_465 (Conv2D)             (None, 8, 8, 128)    147584      activation_426[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_427 (BatchN (None, 8, 8, 128)    512         conv2d_465[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_427 (Activation)     (None, 8, 8, 128)    0           batch_normalization_427[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_466 (Conv2D)             (None, 8, 8, 512)    66048       activation_427[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_139 (Add)                   (None, 8, 8, 512)    0           add_138[0][0]                    \n",
      "                                                                 conv2d_466[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_428 (BatchN (None, 8, 8, 512)    2048        add_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_428 (Activation)     (None, 8, 8, 512)    0           batch_normalization_428[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_467 (Conv2D)             (None, 4, 4, 256)    131328      activation_428[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_429 (BatchN (None, 4, 4, 256)    1024        conv2d_467[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_429 (Activation)     (None, 4, 4, 256)    0           batch_normalization_429[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_468 (Conv2D)             (None, 4, 4, 256)    590080      activation_429[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_430 (BatchN (None, 4, 4, 256)    1024        conv2d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_430 (Activation)     (None, 4, 4, 256)    0           batch_normalization_430[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_470 (Conv2D)             (None, 4, 4, 1024)   525312      add_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_469 (Conv2D)             (None, 4, 4, 1024)   263168      activation_430[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_140 (Add)                   (None, 4, 4, 1024)   0           conv2d_470[0][0]                 \n",
      "                                                                 conv2d_469[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_431 (BatchN (None, 4, 4, 1024)   4096        add_140[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_431 (Activation)     (None, 4, 4, 1024)   0           batch_normalization_431[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_471 (Conv2D)             (None, 4, 4, 256)    262400      activation_431[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_432 (BatchN (None, 4, 4, 256)    1024        conv2d_471[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_432 (Activation)     (None, 4, 4, 256)    0           batch_normalization_432[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_472 (Conv2D)             (None, 4, 4, 256)    590080      activation_432[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_433 (BatchN (None, 4, 4, 256)    1024        conv2d_472[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_433 (Activation)     (None, 4, 4, 256)    0           batch_normalization_433[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_473 (Conv2D)             (None, 4, 4, 1024)   263168      activation_433[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_141 (Add)                   (None, 4, 4, 1024)   0           add_140[0][0]                    \n",
      "                                                                 conv2d_473[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_434 (BatchN (None, 4, 4, 1024)   4096        add_141[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_434 (Activation)     (None, 4, 4, 1024)   0           batch_normalization_434[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_474 (Conv2D)             (None, 4, 4, 256)    262400      activation_434[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_435 (BatchN (None, 4, 4, 256)    1024        conv2d_474[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_435 (Activation)     (None, 4, 4, 256)    0           batch_normalization_435[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_475 (Conv2D)             (None, 4, 4, 256)    590080      activation_435[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_436 (BatchN (None, 4, 4, 256)    1024        conv2d_475[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_436 (Activation)     (None, 4, 4, 256)    0           batch_normalization_436[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_476 (Conv2D)             (None, 4, 4, 1024)   263168      activation_436[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_142 (Add)                   (None, 4, 4, 1024)   0           add_141[0][0]                    \n",
      "                                                                 conv2d_476[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_437 (BatchN (None, 4, 4, 1024)   4096        add_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_437 (Activation)     (None, 4, 4, 1024)   0           batch_normalization_437[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_477 (Conv2D)             (None, 4, 4, 256)    262400      activation_437[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_438 (BatchN (None, 4, 4, 256)    1024        conv2d_477[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_438 (Activation)     (None, 4, 4, 256)    0           batch_normalization_438[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_478 (Conv2D)             (None, 4, 4, 256)    590080      activation_438[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_439 (BatchN (None, 4, 4, 256)    1024        conv2d_478[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_439 (Activation)     (None, 4, 4, 256)    0           batch_normalization_439[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_479 (Conv2D)             (None, 4, 4, 1024)   263168      activation_439[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_143 (Add)                   (None, 4, 4, 1024)   0           add_142[0][0]                    \n",
      "                                                                 conv2d_479[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_440 (BatchN (None, 4, 4, 1024)   4096        add_143[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_440 (Activation)     (None, 4, 4, 1024)   0           batch_normalization_440[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_480 (Conv2D)             (None, 4, 4, 256)    262400      activation_440[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_441 (BatchN (None, 4, 4, 256)    1024        conv2d_480[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_441 (Activation)     (None, 4, 4, 256)    0           batch_normalization_441[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_481 (Conv2D)             (None, 4, 4, 256)    590080      activation_441[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_442 (BatchN (None, 4, 4, 256)    1024        conv2d_481[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_442 (Activation)     (None, 4, 4, 256)    0           batch_normalization_442[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_482 (Conv2D)             (None, 4, 4, 1024)   263168      activation_442[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_144 (Add)                   (None, 4, 4, 1024)   0           add_143[0][0]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 conv2d_482[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_443 (BatchN (None, 4, 4, 1024)   4096        add_144[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_443 (Activation)     (None, 4, 4, 1024)   0           batch_normalization_443[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_483 (Conv2D)             (None, 4, 4, 256)    262400      activation_443[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_444 (BatchN (None, 4, 4, 256)    1024        conv2d_483[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_444 (Activation)     (None, 4, 4, 256)    0           batch_normalization_444[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_484 (Conv2D)             (None, 4, 4, 256)    590080      activation_444[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_445 (BatchN (None, 4, 4, 256)    1024        conv2d_484[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_445 (Activation)     (None, 4, 4, 256)    0           batch_normalization_445[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_485 (Conv2D)             (None, 4, 4, 1024)   263168      activation_445[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_145 (Add)                   (None, 4, 4, 1024)   0           add_144[0][0]                    \n",
      "                                                                 conv2d_485[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_446 (BatchN (None, 4, 4, 1024)   4096        add_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_446 (Activation)     (None, 4, 4, 1024)   0           batch_normalization_446[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_486 (Conv2D)             (None, 2, 2, 512)    524800      activation_446[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_447 (BatchN (None, 2, 2, 512)    2048        conv2d_486[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_447 (Activation)     (None, 2, 2, 512)    0           batch_normalization_447[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_487 (Conv2D)             (None, 2, 2, 512)    2359808     activation_447[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_448 (BatchN (None, 2, 2, 512)    2048        conv2d_487[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_448 (Activation)     (None, 2, 2, 512)    0           batch_normalization_448[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_489 (Conv2D)             (None, 2, 2, 2048)   2099200     add_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_488 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_448[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_146 (Add)                   (None, 2, 2, 2048)   0           conv2d_489[0][0]                 \n",
      "                                                                 conv2d_488[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_449 (BatchN (None, 2, 2, 2048)   8192        add_146[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_449 (Activation)     (None, 2, 2, 2048)   0           batch_normalization_449[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_490 (Conv2D)             (None, 2, 2, 512)    1049088     activation_449[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_450 (BatchN (None, 2, 2, 512)    2048        conv2d_490[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_450 (Activation)     (None, 2, 2, 512)    0           batch_normalization_450[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_491 (Conv2D)             (None, 2, 2, 512)    2359808     activation_450[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_451 (BatchN (None, 2, 2, 512)    2048        conv2d_491[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_451 (Activation)     (None, 2, 2, 512)    0           batch_normalization_451[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_492 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_451[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_147 (Add)                   (None, 2, 2, 2048)   0           add_146[0][0]                    \n",
      "                                                                 conv2d_492[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_452 (BatchN (None, 2, 2, 2048)   8192        add_147[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_452 (Activation)     (None, 2, 2, 2048)   0           batch_normalization_452[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_493 (Conv2D)             (None, 2, 2, 512)    1049088     activation_452[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_453 (BatchN (None, 2, 2, 512)    2048        conv2d_493[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_453 (Activation)     (None, 2, 2, 512)    0           batch_normalization_453[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_494 (Conv2D)             (None, 2, 2, 512)    2359808     activation_453[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_454 (BatchN (None, 2, 2, 512)    2048        conv2d_494[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_454 (Activation)     (None, 2, 2, 512)    0           batch_normalization_454[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_495 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_454[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_148 (Add)                   (None, 2, 2, 2048)   0           add_147[0][0]                    \n",
      "                                                                 conv2d_495[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_455 (BatchN (None, 2, 2, 2048)   8192        add_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_455 (Activation)     (None, 2, 2, 2048)   0           batch_normalization_455[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 1, 1, 2048)   0           activation_455[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 2048)         0           average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 5)            10245       flatten_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 23,582,597\n",
      "Trainable params: 23,537,157\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 316s 4s/step - loss: 6.3838 - acc: 0.4740\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 254s 3s/step - loss: 5.1265 - acc: 0.5445\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 246s 3s/step - loss: 4.2032 - acc: 0.5987\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 247s 3s/step - loss: 3.5585 - acc: 0.6086\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 245s 3s/step - loss: 3.0523 - acc: 0.6239\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 242s 3s/step - loss: 2.7236 - acc: 0.6267\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 239s 3s/step - loss: 2.4696 - acc: 0.6249\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 239s 3s/step - loss: 2.1907 - acc: 0.6682\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 236s 3s/step - loss: 2.0089 - acc: 0.6851\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 236s 3s/step - loss: 1.8940 - acc: 0.6818\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 235s 3s/step - loss: 1.8071 - acc: 0.6714\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 236s 3s/step - loss: 1.7015 - acc: 0.6724\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 235s 3s/step - loss: 1.6294 - acc: 0.6736\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 237s 3s/step - loss: 1.5205 - acc: 0.7020\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 236s 3s/step - loss: 1.4846 - acc: 0.7002\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 240s 3s/step - loss: 1.4185 - acc: 0.6972\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 236s 3s/step - loss: 1.3202 - acc: 0.7239\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 237s 3s/step - loss: 1.3466 - acc: 0.7034\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 235s 3s/step - loss: 1.3025 - acc: 0.7047\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 237s 3s/step - loss: 1.2476 - acc: 0.7159\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 238s 3s/step - loss: 1.2723 - acc: 0.7141\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 238s 3s/step - loss: 1.2494 - acc: 0.7040\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 236s 3s/step - loss: 1.2767 - acc: 0.6883\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 236s 3s/step - loss: 1.2362 - acc: 0.6903\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 237s 3s/step - loss: 1.1288 - acc: 0.7391\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 237s 3s/step - loss: 1.1546 - acc: 0.7247\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 237s 3s/step - loss: 1.2376 - acc: 0.6895\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 237s 3s/step - loss: 1.1406 - acc: 0.7221\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 237s 3s/step - loss: 1.0720 - acc: 0.7352\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 239s 3s/step - loss: 1.1030 - acc: 0.7185\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 239s 3s/step - loss: 1.0285 - acc: 0.7553\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 239s 3s/step - loss: 1.0241 - acc: 0.7492\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 238s 3s/step - loss: 1.0189 - acc: 0.7610\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 236s 3s/step - loss: 1.0419 - acc: 0.7436\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 237s 3s/step - loss: 1.0127 - acc: 0.7631\n",
      "Epoch 36/100\n",
      "88/88 [==============================] - 239s 3s/step - loss: 1.0772 - acc: 0.7322\n",
      "Epoch 37/100\n",
      "88/88 [==============================] - 238s 3s/step - loss: 0.9554 - acc: 0.7675\n",
      "Epoch 38/100\n",
      "88/88 [==============================] - 238s 3s/step - loss: 1.0292 - acc: 0.7444\n",
      "Epoch 39/100\n",
      "88/88 [==============================] - 238s 3s/step - loss: 0.9921 - acc: 0.7556\n",
      "Epoch 40/100\n",
      "88/88 [==============================] - 238s 3s/step - loss: 0.9950 - acc: 0.7599\n",
      "Epoch 41/100\n",
      "88/88 [==============================] - 236s 3s/step - loss: 0.9910 - acc: 0.7485\n",
      "Epoch 42/100\n",
      "88/88 [==============================] - 237s 3s/step - loss: 0.9485 - acc: 0.7731\n",
      "Epoch 43/100\n",
      "88/88 [==============================] - 238s 3s/step - loss: 0.9354 - acc: 0.7675\n",
      "Epoch 44/100\n",
      "88/88 [==============================] - 238s 3s/step - loss: 0.9374 - acc: 0.7606\n",
      "Epoch 45/100\n",
      "88/88 [==============================] - 237s 3s/step - loss: 0.9069 - acc: 0.7789\n",
      "Epoch 46/100\n",
      "88/88 [==============================] - 237s 3s/step - loss: 0.8996 - acc: 0.7757\n",
      "Epoch 47/100\n",
      "88/88 [==============================] - 240s 3s/step - loss: 0.8878 - acc: 0.7830\n",
      "Epoch 48/100\n",
      "88/88 [==============================] - 238s 3s/step - loss: 0.9482 - acc: 0.7661\n",
      "Epoch 49/100\n",
      "88/88 [==============================] - 237s 3s/step - loss: 0.8639 - acc: 0.7952\n",
      "Epoch 50/100\n",
      "88/88 [==============================] - 238s 3s/step - loss: 0.8674 - acc: 0.7896\n",
      "Epoch 51/100\n",
      "88/88 [==============================] - 244s 3s/step - loss: 0.8677 - acc: 0.7876\n",
      "Epoch 52/100\n",
      "88/88 [==============================] - 242s 3s/step - loss: 0.8685 - acc: 0.7819\n",
      "Epoch 53/100\n",
      "88/88 [==============================] - 241s 3s/step - loss: 0.8500 - acc: 0.7961\n",
      "Epoch 54/100\n",
      "88/88 [==============================] - 235s 3s/step - loss: 0.8731 - acc: 0.7798\n",
      "Epoch 55/100\n",
      "88/88 [==============================] - 234s 3s/step - loss: 0.8642 - acc: 0.7812\n",
      "Epoch 56/100\n",
      "88/88 [==============================] - 233s 3s/step - loss: 0.8352 - acc: 0.8011\n",
      "Epoch 57/100\n",
      "88/88 [==============================] - 233s 3s/step - loss: 0.8396 - acc: 0.7942\n",
      "Epoch 58/100\n",
      "88/88 [==============================] - 232s 3s/step - loss: 0.8334 - acc: 0.7942\n",
      "Epoch 59/100\n",
      "88/88 [==============================] - 231s 3s/step - loss: 0.8460 - acc: 0.7951\n",
      "Epoch 60/100\n",
      "88/88 [==============================] - 231s 3s/step - loss: 0.8564 - acc: 0.7961\n",
      "Epoch 61/100\n",
      "88/88 [==============================] - 231s 3s/step - loss: 0.8504 - acc: 0.7844\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 62/100\n",
      "88/88 [==============================] - 244s 3s/step - loss: 0.7922 - acc: 0.8093\n",
      "Epoch 63/100\n",
      "88/88 [==============================] - 230s 3s/step - loss: 0.6995 - acc: 0.8398\n",
      "Epoch 64/100\n",
      "88/88 [==============================] - 233s 3s/step - loss: 0.7101 - acc: 0.8300\n",
      "Epoch 65/100\n",
      "88/88 [==============================] - 230s 3s/step - loss: 0.6927 - acc: 0.8352\n",
      "Epoch 66/100\n",
      "88/88 [==============================] - 230s 3s/step - loss: 0.7211 - acc: 0.8361\n",
      "Epoch 67/100\n",
      "88/88 [==============================] - 233s 3s/step - loss: 0.6441 - acc: 0.8544\n",
      "Epoch 68/100\n",
      "88/88 [==============================] - 231s 3s/step - loss: 0.6508 - acc: 0.8480\n",
      "Epoch 69/100\n",
      "88/88 [==============================] - 243s 3s/step - loss: 0.6734 - acc: 0.8400\n",
      "Epoch 70/100\n",
      "88/88 [==============================] - 257s 3s/step - loss: 0.6688 - acc: 0.8428\n",
      "Epoch 71/100\n",
      "88/88 [==============================] - 239s 3s/step - loss: 0.6322 - acc: 0.8560\n",
      "Epoch 72/100\n",
      "88/88 [==============================] - 236s 3s/step - loss: 0.6151 - acc: 0.8689\n",
      "Epoch 73/100\n",
      "88/88 [==============================] - 235s 3s/step - loss: 0.6400 - acc: 0.8587\n",
      "Epoch 74/100\n",
      "88/88 [==============================] - 233s 3s/step - loss: 0.6107 - acc: 0.8654\n",
      "Epoch 75/100\n",
      "88/88 [==============================] - 242s 3s/step - loss: 0.6678 - acc: 0.8426\n",
      "Epoch 76/100\n",
      "88/88 [==============================] - 236s 3s/step - loss: 0.6192 - acc: 0.8565\n",
      "Epoch 77/100\n",
      "88/88 [==============================] - 246s 3s/step - loss: 0.6243 - acc: 0.8578\n",
      "Epoch 78/100\n",
      "88/88 [==============================] - 254s 3s/step - loss: 0.5795 - acc: 0.8716\n",
      "Epoch 79/100\n",
      "88/88 [==============================] - 249s 3s/step - loss: 0.6037 - acc: 0.8649\n",
      "Epoch 80/100\n",
      "88/88 [==============================] - 240s 3s/step - loss: 0.6122 - acc: 0.8617\n",
      "Epoch 81/100\n",
      "88/88 [==============================] - 233s 3s/step - loss: 0.5939 - acc: 0.8663\n",
      "Epoch 82/100\n",
      "88/88 [==============================] - 236s 3s/step - loss: 0.5613 - acc: 0.8761\n",
      "Epoch 83/100\n",
      "88/88 [==============================] - 233s 3s/step - loss: 0.6153 - acc: 0.8631\n",
      "Epoch 84/100\n",
      "88/88 [==============================] - 232s 3s/step - loss: 0.5731 - acc: 0.8771\n",
      "Epoch 85/100\n",
      "88/88 [==============================] - 233s 3s/step - loss: 0.6000 - acc: 0.8698\n",
      "Epoch 86/100\n",
      "88/88 [==============================] - 232s 3s/step - loss: 0.5810 - acc: 0.8780\n",
      "Epoch 87/100\n",
      "88/88 [==============================] - 232s 3s/step - loss: 0.5545 - acc: 0.8840\n",
      "Epoch 88/100\n",
      "88/88 [==============================] - 232s 3s/step - loss: 0.6201 - acc: 0.8597\n",
      "Epoch 89/100\n",
      "88/88 [==============================] - 233s 3s/step - loss: 0.5607 - acc: 0.8830\n",
      "Epoch 90/100\n",
      "88/88 [==============================] - 233s 3s/step - loss: 0.5419 - acc: 0.8888\n",
      "Epoch 91/100\n",
      "88/88 [==============================] - 233s 3s/step - loss: 0.5989 - acc: 0.8650\n",
      "Epoch 92/100\n",
      "88/88 [==============================] - 235s 3s/step - loss: 0.5536 - acc: 0.8807\n",
      "Epoch 93/100\n",
      "88/88 [==============================] - 234s 3s/step - loss: 0.5600 - acc: 0.8787\n",
      "Epoch 94/100\n",
      "88/88 [==============================] - 234s 3s/step - loss: 0.5529 - acc: 0.8833\n",
      "Epoch 95/100\n",
      "88/88 [==============================] - 234s 3s/step - loss: 0.5218 - acc: 0.8894\n",
      "Epoch 96/100\n",
      "88/88 [==============================] - 234s 3s/step - loss: 0.5177 - acc: 0.8927\n",
      "Epoch 97/100\n",
      "88/88 [==============================] - 238s 3s/step - loss: 0.5404 - acc: 0.8874\n",
      "Epoch 98/100\n",
      "88/88 [==============================] - 234s 3s/step - loss: 0.5312 - acc: 0.8853\n",
      "Epoch 99/100\n",
      "88/88 [==============================] - 233s 3s/step - loss: 0.5228 - acc: 0.8929\n",
      "Epoch 100/100\n",
      "88/88 [==============================] - 233s 3s/step - loss: 0.5268 - acc: 0.8902\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x199d9559b0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use resnet 50\n",
    "clf = ResnetBuilder.build_resnet_50(input_shape=(3,64,64), num_outputs=num_classes)\n",
    "clf.summary()\n",
    "clf.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "clf.fit_generator(train,\n",
    "                  steps_per_epoch = int(total_samples/batch_size),\n",
    "                  epochs = 100,\n",
    "                  verbose=1,\n",
    "                  shuffle=True,\n",
    "                  callbacks=[earlystop, reduce_lr]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 213s 106ms/step\n"
     ]
    }
   ],
   "source": [
    "export_results(train,test, clf, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_412 (Conv2D)             (None, 64, 64, 16)   448         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_379 (BatchN (None, 64, 64, 16)   64          conv2d_412[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, 64, 64, 16)   0           batch_normalization_379[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_413 (Conv2D)             (None, 64, 64, 16)   272         activation_379[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_380 (BatchN (None, 64, 64, 16)   64          conv2d_413[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, 64, 64, 16)   0           batch_normalization_380[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_414 (Conv2D)             (None, 64, 64, 16)   2320        activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_381 (BatchN (None, 64, 64, 16)   64          conv2d_414[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, 64, 64, 16)   0           batch_normalization_381[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_416 (Conv2D)             (None, 64, 64, 64)   1088        activation_379[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_415 (Conv2D)             (None, 64, 64, 64)   1088        activation_381[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_124 (Add)                   (None, 64, 64, 64)   0           conv2d_416[0][0]                 \n",
      "                                                                 conv2d_415[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_382 (BatchN (None, 64, 64, 64)   256         add_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_382 (Activation)     (None, 64, 64, 64)   0           batch_normalization_382[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_417 (Conv2D)             (None, 64, 64, 16)   1040        activation_382[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_383 (BatchN (None, 64, 64, 16)   64          conv2d_417[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_383 (Activation)     (None, 64, 64, 16)   0           batch_normalization_383[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_418 (Conv2D)             (None, 64, 64, 16)   2320        activation_383[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_384 (BatchN (None, 64, 64, 16)   64          conv2d_418[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_384 (Activation)     (None, 64, 64, 16)   0           batch_normalization_384[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_419 (Conv2D)             (None, 64, 64, 64)   1088        activation_384[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_125 (Add)                   (None, 64, 64, 64)   0           add_124[0][0]                    \n",
      "                                                                 conv2d_419[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_385 (BatchN (None, 64, 64, 64)   256         add_125[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_385 (Activation)     (None, 64, 64, 64)   0           batch_normalization_385[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_420 (Conv2D)             (None, 64, 64, 16)   1040        activation_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_386 (BatchN (None, 64, 64, 16)   64          conv2d_420[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_386 (Activation)     (None, 64, 64, 16)   0           batch_normalization_386[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_421 (Conv2D)             (None, 64, 64, 16)   2320        activation_386[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_387 (BatchN (None, 64, 64, 16)   64          conv2d_421[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_387 (Activation)     (None, 64, 64, 16)   0           batch_normalization_387[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_422 (Conv2D)             (None, 64, 64, 64)   1088        activation_387[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_126 (Add)                   (None, 64, 64, 64)   0           add_125[0][0]                    \n",
      "                                                                 conv2d_422[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_388 (BatchN (None, 64, 64, 64)   256         add_126[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_388 (Activation)     (None, 64, 64, 64)   0           batch_normalization_388[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_423 (Conv2D)             (None, 32, 32, 64)   4160        activation_388[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_389 (BatchN (None, 32, 32, 64)   256         conv2d_423[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_389 (Activation)     (None, 32, 32, 64)   0           batch_normalization_389[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_424 (Conv2D)             (None, 32, 32, 64)   36928       activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_390 (BatchN (None, 32, 32, 64)   256         conv2d_424[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_390 (Activation)     (None, 32, 32, 64)   0           batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_426 (Conv2D)             (None, 32, 32, 128)  8320        add_126[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_425 (Conv2D)             (None, 32, 32, 128)  8320        activation_390[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_127 (Add)                   (None, 32, 32, 128)  0           conv2d_426[0][0]                 \n",
      "                                                                 conv2d_425[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_391 (BatchN (None, 32, 32, 128)  512         add_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_391 (Activation)     (None, 32, 32, 128)  0           batch_normalization_391[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_427 (Conv2D)             (None, 32, 32, 64)   8256        activation_391[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_392 (BatchN (None, 32, 32, 64)   256         conv2d_427[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_392 (Activation)     (None, 32, 32, 64)   0           batch_normalization_392[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_428 (Conv2D)             (None, 32, 32, 64)   36928       activation_392[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_393 (BatchN (None, 32, 32, 64)   256         conv2d_428[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_393 (Activation)     (None, 32, 32, 64)   0           batch_normalization_393[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_429 (Conv2D)             (None, 32, 32, 128)  8320        activation_393[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_128 (Add)                   (None, 32, 32, 128)  0           add_127[0][0]                    \n",
      "                                                                 conv2d_429[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_394 (BatchN (None, 32, 32, 128)  512         add_128[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_394 (Activation)     (None, 32, 32, 128)  0           batch_normalization_394[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_430 (Conv2D)             (None, 32, 32, 64)   8256        activation_394[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_395 (BatchN (None, 32, 32, 64)   256         conv2d_430[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_395 (Activation)     (None, 32, 32, 64)   0           batch_normalization_395[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_431 (Conv2D)             (None, 32, 32, 64)   36928       activation_395[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_396 (BatchN (None, 32, 32, 64)   256         conv2d_431[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_396 (Activation)     (None, 32, 32, 64)   0           batch_normalization_396[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_432 (Conv2D)             (None, 32, 32, 128)  8320        activation_396[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_129 (Add)                   (None, 32, 32, 128)  0           add_128[0][0]                    \n",
      "                                                                 conv2d_432[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_397 (BatchN (None, 32, 32, 128)  512         add_129[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_397 (Activation)     (None, 32, 32, 128)  0           batch_normalization_397[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_433 (Conv2D)             (None, 16, 16, 128)  16512       activation_397[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_398 (BatchN (None, 16, 16, 128)  512         conv2d_433[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_398 (Activation)     (None, 16, 16, 128)  0           batch_normalization_398[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_434 (Conv2D)             (None, 16, 16, 128)  147584      activation_398[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_399 (BatchN (None, 16, 16, 128)  512         conv2d_434[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_399 (Activation)     (None, 16, 16, 128)  0           batch_normalization_399[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_436 (Conv2D)             (None, 16, 16, 256)  33024       add_129[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_435 (Conv2D)             (None, 16, 16, 256)  33024       activation_399[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_130 (Add)                   (None, 16, 16, 256)  0           conv2d_436[0][0]                 \n",
      "                                                                 conv2d_435[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_400 (BatchN (None, 16, 16, 256)  1024        add_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_400 (Activation)     (None, 16, 16, 256)  0           batch_normalization_400[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_437 (Conv2D)             (None, 16, 16, 128)  32896       activation_400[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_401 (BatchN (None, 16, 16, 128)  512         conv2d_437[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_401 (Activation)     (None, 16, 16, 128)  0           batch_normalization_401[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_438 (Conv2D)             (None, 16, 16, 128)  147584      activation_401[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_402 (BatchN (None, 16, 16, 128)  512         conv2d_438[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_402 (Activation)     (None, 16, 16, 128)  0           batch_normalization_402[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_439 (Conv2D)             (None, 16, 16, 256)  33024       activation_402[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_131 (Add)                   (None, 16, 16, 256)  0           add_130[0][0]                    \n",
      "                                                                 conv2d_439[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_403 (BatchN (None, 16, 16, 256)  1024        add_131[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_403 (Activation)     (None, 16, 16, 256)  0           batch_normalization_403[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_440 (Conv2D)             (None, 16, 16, 128)  32896       activation_403[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_404 (BatchN (None, 16, 16, 128)  512         conv2d_440[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_404 (Activation)     (None, 16, 16, 128)  0           batch_normalization_404[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_441 (Conv2D)             (None, 16, 16, 128)  147584      activation_404[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_405 (BatchN (None, 16, 16, 128)  512         conv2d_441[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_405 (Activation)     (None, 16, 16, 128)  0           batch_normalization_405[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_442 (Conv2D)             (None, 16, 16, 256)  33024       activation_405[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_132 (Add)                   (None, 16, 16, 256)  0           add_131[0][0]                    \n",
      "                                                                 conv2d_442[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_406 (BatchN (None, 16, 16, 256)  1024        add_132[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_406 (Activation)     (None, 16, 16, 256)  0           batch_normalization_406[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 2, 2, 256)    0           activation_406[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 1024)         0           average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 5)            5125        flatten_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 851,557\n",
      "Trainable params: 846,341\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2322\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2323\u001b[0;31m         \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2324\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'batch_normalization_402/FusedBatchNorm' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m       \u001b[0mxla_compile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaCompile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2326\u001b[0m       \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2327\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2328\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation 'batch_normalization_402/FusedBatchNorm' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-f1b0b016f5ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                   \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                   )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    507\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    508\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    510\u001b[0m                 updates = (self.updates +\n\u001b[1;32m    511\u001b[0m                            \u001b[0mtraining_updates\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             raise ValueError('An operation has `None` for gradient. '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   2755\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m     \"\"\"\n\u001b[0;32m-> 2757\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[1;32m    628\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n\u001b[0;32m--> 630\u001b[0;31m                             gate_gradients, aggregation_method, stop_gradients)\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, src_graph)\u001b[0m\n\u001b[1;32m    812\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 814\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    815\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    406\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaScope\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    812\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 814\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    815\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_FusedBatchNormGrad\u001b[0;34m(op, *grad)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FusedBatchNorm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_FusedBatchNormGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_BaseFusedBatchNormGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_BaseFusedBatchNormGrad\u001b[0;34m(op, use_v2, *grad)\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         is_training=is_training)\n\u001b[0m\u001b[1;32m    800\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[0mpop_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mfused_batch_norm_grad\u001b[0;34m(y_backprop, x, scale, reserve_space_1, reserve_space_2, epsilon, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   3574\u001b[0m     \u001b[0mreserve_space_4\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my_backprop\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3575\u001b[0m   \"\"\"\n\u001b[0;32m-> 3576\u001b[0;31m   \u001b[0m_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3577\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Transfer learning using resnet\n",
    "model_resnet = resnet(input_shape=(64,64,3), num_classes=num_classes)\n",
    "model_resnet.summary()\n",
    "model_resnet.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "model_resnet.fit_generator(train,\n",
    "                  steps_per_epoch = 1, #int(total_samples/batch_size),\n",
    "                  epochs = 2, # change from 50\n",
    "                  verbose=1,\n",
    "                  shuffle=True,\n",
    "                  callbacks=[earlystop, reduce_lr]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_results(train,test, model_resnet, 2222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = (train.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "test_path=test.filenames\n",
    "filenames=[]\n",
    "for n in test_path:\n",
    "    seg1, seg2 = n.split(\"/\")\n",
    "    front, back = seg2.split('.')\n",
    "    \n",
    "    filenames.append(front)\n",
    "\n",
    "results= pd.DataFrame({\"id\":filenames,\n",
    "                  \"flower_class\":predicted_class_indices})\n",
    "results.to_csv(\"./submission4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "test_path=test.filenames\n",
    "filenames=[]\n",
    "for n in test_path:\n",
    "    seg1, seg2 = n.split(\"/\")\n",
    "    front, back = seg2.split('.')\n",
    "    \n",
    "    filenames.append(front)\n",
    "\n",
    "results= pd.DataFrame({\"id\":filenames,\n",
    "                  \"flower_class\":predicted_class_indices})\n",
    "results.to_csv(\"./submission4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = pd.DataFrame()\n",
    "a=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.to_csv(\"./test\"+str(a)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_166 (Conv2D)          (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_167 (Conv2D)          (None, 62, 62, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_168 (Conv2D)          (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_169 (Conv2D)          (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 2565      \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 6,501,285\n",
      "Trainable params: 6,501,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build Model\n",
    "\n",
    "clf = Sequential()\n",
    "clf.add(Conv2D(64, (3, 3), padding='same',\n",
    "                 input_shape=(64,64,3)))\n",
    "clf.add(Activation('relu'))\n",
    "clf.add(Conv2D(32, (3, 3)))\n",
    "clf.add(Activation('relu'))\n",
    "clf.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "clf.add(Dropout(0.25))\n",
    "\n",
    "clf.add(Conv2D(64, (3, 3), padding='same'))\n",
    "clf.add(Activation('relu'))\n",
    "clf.add(Conv2D(64, (3, 3)))\n",
    "clf.add(Activation('relu'))\n",
    "clf.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "clf.add(Dropout(0.25))\n",
    "\n",
    "clf.add(Flatten())\n",
    "clf.add(Dense(512))\n",
    "clf.add(Activation('relu'))\n",
    "clf.add(Dropout(0.5))\n",
    "clf.add(Dense(num_classes))\n",
    "clf.add(Activation('softmax'))\n",
    "clf.summary()\n",
    "clf.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "88/88 [==============================] - 89s 1s/step - loss: 1.5526 - acc: 0.3261\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 91s 1s/step - loss: 1.2736 - acc: 0.4534\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 85s 971ms/step - loss: 1.1690 - acc: 0.5303\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 86s 975ms/step - loss: 1.1042 - acc: 0.5664\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 87s 992ms/step - loss: 1.0144 - acc: 0.6026\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 86s 973ms/step - loss: 1.0234 - acc: 0.6079\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 86s 974ms/step - loss: 0.9508 - acc: 0.6397\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 85s 971ms/step - loss: 0.9394 - acc: 0.6546\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 86s 979ms/step - loss: 0.9315 - acc: 0.6446\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 88s 1s/step - loss: 0.9080 - acc: 0.6486\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 89s 1s/step - loss: 0.8999 - acc: 0.6644\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 88s 998ms/step - loss: 0.8958 - acc: 0.6779\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 89s 1s/step - loss: 0.8495 - acc: 0.6811\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 88s 999ms/step - loss: 0.8524 - acc: 0.6809\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 88s 996ms/step - loss: 0.8481 - acc: 0.6883\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 88s 1000ms/step - loss: 0.8225 - acc: 0.6972\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 91s 1s/step - loss: 0.8223 - acc: 0.7011\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 90s 1s/step - loss: 0.8108 - acc: 0.7031\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 88s 995ms/step - loss: 0.7765 - acc: 0.7123\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 90s 1s/step - loss: 0.7954 - acc: 0.7022\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 92s 1s/step - loss: 0.7899 - acc: 0.7066\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 94s 1s/step - loss: 0.7838 - acc: 0.7095\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 93s 1s/step - loss: 0.7735 - acc: 0.7159\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 88s 1s/step - loss: 0.7691 - acc: 0.7130\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 87s 983ms/step - loss: 0.7770 - acc: 0.7190\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 87s 984ms/step - loss: 0.7444 - acc: 0.7301\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 87s 989ms/step - loss: 0.7733 - acc: 0.7157\n",
      "Epoch 28/50\n",
      "39/88 [============>.................] - ETA: 48s - loss: 0.7787 - acc: 0.7094"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-c6dbd2a13bf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                   \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                   \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                   )\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf.fit_generator(train,\n",
    "                  steps_per_epoch = int(total_samples/batch_size),\n",
    "                  epochs = 50,\n",
    "                  verbose=1,\n",
    "                  shuffle=True\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'daisy', 1: 'dandelion', 2: 'rose', 3: 'sunflower', 4: 'tulip'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = (train.class_indices)\n",
    "labels = dict((n,l) for l,n in labels.items())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "clf.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# later...\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 45s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "test.reset()\n",
    "pred = clf.predict_generator(test, steps=len(test),verbose=1)\n",
    "predicted_class_indices=np.argmax(pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = (train.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "test_path=test.filenames\n",
    "filenames=[]\n",
    "for n in test_path:\n",
    "    seg1, seg2 = n.split(\"\\\\\")\n",
    "    front, back = seg2.split('.')\n",
    "    \n",
    "    filenames.append(front)\n",
    "\n",
    "results= pd.DataFrame({\"id\":filenames,\n",
    "                  \"flower_class\":predicted_class_indices})\n",
    "results.to_csv(\"./submission2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convolutional_block' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-166acd207a63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m res_model.compile(optimizer='adam', \n\u001b[0;32m      3\u001b[0m                   \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                   metrics=['accuracy'])\n\u001b[0;32m      5\u001b[0m res_model.fit_generator(train,\n",
      "\u001b[1;32m<ipython-input-83-46422db4b3b8>\u001b[0m in \u001b[0;36mResNet50\u001b[1;34m(input_shape, classes)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Stage 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvolutional_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'convolutional_block' is not defined"
     ]
    }
   ],
   "source": [
    "res_model = ResNet50()\n",
    "res_model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "res_model.fit_generator(train,\n",
    "                  steps_per_epoch = int(len(train)/32),\n",
    "                  epochs = 25,\n",
    "                  verbose=1,\n",
    "                  shuffle=True\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\cptien\\\\Desktop\\\\data'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
